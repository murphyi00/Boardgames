---
title: "Group 3 Final Project Code"
output: html_document
date: "2023-06-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(repos = c(CRAN = "https://cran.rstudio.com/"))

```


```{r}
# Load libraries
library(stringdist)
library(plotly)
library(stringr)
library(forcats)
library(ggplot2)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
library(tidyverse)
library(dplyr)
#library(plyr)
library(readr)

# Set options
options(scipen = 999)
```
## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r books}
#books <- read_csv("C:\\Users\\jbeat\\Desktop\\GR Final Proj\\Books_w_genres.csv")

summary(books)
```



```{r}
#Begin data cleaning on relevant fields for use in analysis

books$publication_date <- as.Date(books$publication_date, format = "%m/%d/%Y")
books$average_rating <- as.numeric(books$average_rating)
books$num_pages <- as.numeric(books$num_pages)
books$bookID <- as.numeric(books$bookID)

books_complete <- books[complete.cases(books), ]          #Remove 10 faulty records (0.1% ) in data cleaning effort
summary(books_complete)
```

```{r}
#  Get the publisher field cleaned up with ability to convert it to factors with some accuracy


```

```{r}

# Use a function of quanteda package, tokens(), to make more analysis possible, and put it in a document feature matrix with dfm() 

toks_publisher <- tokens(books_complete$publisher, remove_punct = TRUE)

# Clean the data of insignificant tokens by removing stopwords using token_select()

toks_nostop <- tokens_select(toks_publisher, pattern = stopwords("en"), selection = "remove")


# Remove "inc." from the tokens
toks_nostop <- tokens_remove(toks_nostop, "inc.", case_insensitive = TRUE)

# Create the DFM

dfm_publisher <- dfm(toks_nostop)

```


```{r}
#  Just the words in the publisher names, sorted by frequency for visual analysis
freq_table <- textstat_frequency(dfm_publisher)
head(freq_table, 10)
```

```{r}
#  Look at the wordcloud from the document feature matrix, like in lab 9
#  
textplot_wordcloud(dfm_publisher, min_count = 1) 

```

```{r}
# Implement a method of comparison by first creating a dictionary of publishers from the publishers in the list

# Calculate the cosine similarity matrix

similarity_matrix <- textstat_simil(dfm_publisher, method = "cosine")

# Create an empty mapping dictionary
keyword_mapping <- list()

# Set a threshold for similarity
similarity_threshold <- 0.8

# Loop through each publisher
for (i in 1:nrow(books_complete)) {
  publisher <- books_complete$publisher[i]
  
  # Get the similarity scores for the current publisher
  similarity_scores <- similarity_matrix[i, ]
  
  # Find the indices of the most similar publishers
  most_similar_indices <- which(similarity_scores > similarity_threshold)
  
  # Get the most similar publishers as matched keywords
  matched_keywords <- colnames(similarity_matrix)[most_similar_indices]
  
  # Check if the keywords already exist in the mapping dictionary
  for (keyword in matched_keywords) {
    if (keyword %in% names(keyword_mapping)) {
      # If it exists, append the current publisher to the existing list of publishers
      keyword_mapping[[keyword]] <- c(keyword_mapping[[keyword]], publisher)
    } else {
      # If it doesn't exist, create a new entry in the mapping dictionary
      keyword_mapping[[keyword]] <- publisher
    }
  }
}


```

```{r}

# My main task is to factorize the publisher field based on the keyword mapping, but I'll use a derived variable

# Create a new column for the factorized publisher

books_complete$Factor_publisher <- books_complete$publisher


# Loop through each keyword in the keyword_mapping dictionary
for (keyword in names(keyword_mapping)) {
  # Get the associated publishers for the current keyword
  publishers <- keyword_mapping[[keyword]]
  
  # Factorize the publisher field based on the keyword
  books_complete$Factor_publisher[books_complete$publisher %in% publishers] <- keyword
}

# Convert the Factor_publisher column to a factor
books_complete$Factor_publisher <- as.factor(books_complete$Factor_publisher)

# Get the unique factor levels in the Factor_publisher column
factor_levels <- levels(books_complete$Factor_publisher)

# Rename the factor levels to the contents of text####[1]
for (i in 1:length(factor_levels)) {
  factor_levels[i] <- keyword_mapping[[factor_levels[i]]][1]
}

# Assign the renamed factor levels back to the Factor_publisher column
levels(books_complete$Factor_publisher) <- factor_levels

```




```{r}
#Which authors have the least amount of ratings?

least_ratings <- books_complete %>%
  group_by(authors) %>%
  dplyr::summarize(total_ratings = sum(ratings_count)) %>%
  arrange(total_ratings) %>%
  head(60)

least_ratings #56 authors have 0 ratings


```
```{r}

# Which publishers on the list produce the longest books?

longest_books <- books_complete %>%
  group_by(publisher) %>%
  dplyr::summarize(max_num_pages = max(num_pages)) %>%
  arrange(desc(max_num_pages)) %>%
  head(250)

longest_books # Over a hundred publishers (118 publishers) will publish books over 1000 pages

```

```{r}
#   Which authors publish the most books over time?
top_authors <- books_complete %>%
  group_by(authors) %>%
  dplyr::summarize(total_books = n()) %>%
  arrange(desc(total_books))

print(top_authors)

top_authors <- books_complete %>%
  group_by(authors) %>%
  dplyr::summarize(total_books = n()) %>%
  arrange(desc(total_books)) %>%
  dplyr::mutate(author_rank = row_number())

books_complete <- left_join(books_complete, top_authors, by = "authors")


```

```{r}
#   Which authors publish the most content over time, by page count?
 

top_authors <- books_complete %>%
  group_by(authors) %>%
  dplyr::summarize(total_pages = sum(num_pages)) %>%
  arrange(desc(total_pages))

print(top_authors)

```

```{r}

# Select the top 50 authors based on the total number of pages
top_authors <- books_complete %>%
  group_by(authors) %>%
  dplyr::summarize(total_pages = sum(num_pages)) %>%
  arrange(total_pages) %>%
  top_n(50)

# Create a data frame for the heat map
heatmap_data <- books_complete %>%
  filter(authors %in% top_authors$authors) %>%
  group_by(authors) %>%
  dplyr::summarize(total_books = n(), total_pages = sum(num_pages)) %>%
  arrange(total_pages) # Sort the data frame by total pages

# Create the heat map plot
heatmap <- ggplot(heatmap_data, aes(x = total_books, y = reorder(authors, total_pages), fill = total_pages)) +
  geom_tile() +
  scale_fill_gradient(low = "lightskyblue1", high = "darkblue") +
  labs(title = "Top 50 Authors - Total Number of Pages",
       x = "Total Books", y = "Authors",
       fill = "Total Pages")

heatmap
```

```{r}

favorites_outliers_omitted <- filter(books_complete, ratings_count < 20000, ratings_count > 10)

# Assign colors based on intervals using a gradient 
colors <- colorRampPalette(c("lightskyblue1", "darkblue"))(10)

# Cut author_rank into intervals and assign colors
intervals <- cut(books_complete$author_rank, breaks = 10, labels = FALSE)
colors <- colors[intervals]

# Plot the scatter plot with color-coded points
plot(favorites_outliers_omitted$average_rating, favorites_outliers_omitted$ratings_count,
     col = colors,
     xlab = "Average Rating, Popular Authors Darker",
     ylab = "Ratings Count",
     main = "Scatter Plot of Average Rating vs Ratings Count")


```



```{r}
favorites_outliers_omitted <- filter(books_complete, ratings_count < 20000, ratings_count > 10)


# Assign colors based on intervals using a gradient palette
colors <- colorRampPalette(c("lightskyblue1", "darkblue"))(10)

# Cut author_rank into intervals and assign colors
intervals <- cut(favorites_outliers_omitted$author_rank, breaks = 10, labels = FALSE)
colors <- colors[intervals]

# Create a hover text with additional information
hover_text <- paste("Title: ", favorites_outliers_omitted$title,
                    "<br>Author: ", favorites_outliers_omitted$authors,
                    "<br>Ratings Count: ", favorites_outliers_omitted$ratings_count,
                    "<br>Average Rating: ", favorites_outliers_omitted$average_rating)

# Create a scatter plot with hover information using plot_ly
plot_ly(favorites_outliers_omitted, x = ~average_rating, y = ~ratings_count,
        type = "scatter", mode = "markers",
        color = ~colors, colors = c("lightskyblue1", "darkblue"),
        text = hover_text, hoverinfo = "text") %>%
  layout(xaxis = list(title = "Average Rating"),
         yaxis = list(title = "Ratings Count"),
         title = "Interactive Scatter Plot with Hover Information")


```

```{r}
# Some seem publishers specifically associated with super long books, these are 80% box sets.
longest_books <- books_complete %>%
  group_by(publisher) %>%
  dplyr::summarize(max_pages = max(num_pages),
            author = authors[which.max(num_pages)]) %>%  # Get the title corresponding to the max_pages
  arrange(desc(max_pages))

head(longest_books, 10)  # Display the top 10 publishers with the longest books and their corresponding titles


```

```{r}
# These publishers average book
top_100_publishers <- books_complete %>%
  group_by(publisher) %>%
  dplyr::summarize(total_books = n()) %>%
  arrange(desc(total_books)) %>%
  top_n(100)

longest_books <- books_complete %>%
  filter(publisher %in% top_100_publishers$publisher) %>%
  group_by(publisher) %>%
  dplyr::summarize(average_pages = round(mean(num_pages))) %>%
  arrange(desc(average_pages))

head(longest_books, 10)  # Display the top 10 publishers with the longest books

```




```{r}
#  Most common publishers on the GoodReads site

most_books <- books_complete %>%
  group_by(publisher) %>%
  dplyr::summarize(total_books = n()) %>%
  arrange(desc(total_books))

head(most_books, 10)  # Display the top 10 publishers with the most books

```

```{r}
#  Top 100 authors with the most unique publishers:

# Group the data by authors and count the number of unique publishers for each author
author_publishers <- books_complete %>%
  group_by(authors) %>%
  dplyr::summarize(unique_publishers = n_distinct(publisher))

# Sort the authors by the number of unique publishers in descending order
author_publishers_sorted <- author_publishers %>%
  arrange(desc(unique_publishers))

# Select the top 100 authors with the most unique publishers
top_authors <- head(author_publishers_sorted, 100)

top_authors
```

```{r}
# Use top_authors as judged by how many publishers they work with, and compare ratings with average authors

# Calculate the average rating for each author in the top_authors list
top_authors_with_rating <- top_authors %>%
  left_join(books_complete, by = "authors") %>%
  group_by(authors) %>%
  dplyr::summarize(unique_publishers = n_distinct(publisher), avg_rating = mean(average_rating))

# Sort the authors by the number of unique publishers
top_authors_with_rating <- top_authors_with_rating[order(top_authors_with_rating$unique_publishers, decreasing = TRUE), ]

top_authors_with_rating

```


```{r}
# Calculate the average rating for all the authors in the top 100 list
avg_rating_top_100 <- mean(top_authors_with_rating$avg_rating)

# Print the average rating for all the authors in the top 100 list
cat("Average rating for the top 100 authors:", avg_rating_top_100, "\n")

avg_rating_all_books <- mean(books_complete$average_rating)
cat("Average rating for all books:", avg_rating_all_books, "\n")

```


```{r}
top_authors_avg_rating <- books_complete %>%
  group_by(authors) %>%
  dplyr::summarize(avg_rating = mean(average_rating),
            total_reviews = sum(text_reviews_count)) %>%
  filter(avg_rating > 4.5) %>%
  arrange(desc(total_reviews)) %>%
  top_n(30)

top_authors_avg_rating
```

```{r}
# Truncate author names to fit the plot
top_authors_avg_rating$truncated_authors <- ifelse(nchar(top_authors_avg_rating$authors) > 25,
                                                   substr(top_authors_avg_rating$authors, 1, 25),
                                                   top_authors_avg_rating$authors)

ggplot(top_authors_avg_rating, aes(x = reorder(truncated_authors, -total_reviews), y = log(total_reviews), fill = avg_rating)) +
  geom_col() +
  geom_text(aes(label = total_reviews), vjust = -0.5, size = 3, angle = 45) +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "Top Authors - Average Rating and Total Reviews",
       x = "Authors",
       y = "Log(Total Reviews)") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```

```{r}
# Top 10 Books (Ratings > 500)
#Generates variable with unwanted words
exclWords <- c('Complete', 'Collection', 'Box', 'Collected', 'box set')

# Filters out low review counts, anonymous authors, and unwanted values
top10 <- books_complete %>%
  filter(average_rating >= 4.5, ratings_count > 500) %>%
  filter(!grepl(paste('/', collapse='|'), authors)) %>%
  filter(!grepl(paste('Anonymous', collapse='|'), authors)) %>%
  filter(!grepl(paste(exclWords, collapse='|'), title))

# Orders remaining reviews and pulls top 10
top10 <- top10 %>% 
  arrange(-average_rating) %>% 
  head(10)

# Bottom 10 Books (Ratings > 500)
# Filters out low reviews and unwanted values
bot10 <- books_complete %>%
  filter(ratings_count > 500) %>%
  filter(!grepl(paste(exclWords, collapse='|'), title))


# Orders remaining and pull bot 10
bot10 <- bot10 %>% 
  arrange(average_rating) %>% 
  head(10)
```

```{r}
# Plots top 10 books by rating
top10Bar <-ggplot(data=top10, aes(x=average_rating, y=title)) +
  geom_bar(stat="identity", fill='steelblue4', width=0.7) +
  xlim(0,5) +
  geom_text(aes(label=average_rating), hjust=1.3, color='white', size=3.5) +
  ggtitle('Top 10 Books by Rating') +
  xlab('Average Rating') +
  ylab('Book Title')
top10Bar

# Plots bot 10 books by rating
bot10Bar <-ggplot(data=bot10, aes(x=average_rating, y=title)) +
  geom_bar(stat="identity", fill='steelblue4', width=0.7) +
  xlim(0,5) +
  geom_text(aes(label=average_rating), hjust=1.3, color='white', size=3.5) +
  ggtitle('Bottom 10 Books by Rating') +
  xlab('Average Rating') +
  ylab('Book Title')
bot10Bar
```

```{r}
# Get average rating of all authors
# Filter out books with multiple authors (for clarity)
avgRatings <- books_complete %>%
  filter(!grepl(paste('/', collapse='|'), authors)) %>%
  filter(!grepl(paste('Anonymous', collapse='|'), authors))

# Extract only necessary columns
avgRatings = avgRatings[, c(3,4)]

# Group authors and calculate mean of their reviews
avgRatings <- avgRatings %>%
                group_by(authors) %>%
                dplyr::summarise(mean = mean(average_rating),
                      sd = sd(average_rating)) %>%
                mutate(cv = (sd/mean)*100)

# Limits decimal to 2 places
avgRatings$mean <- format(round(avgRatings$mean, 2), nsmall = 2)
```

```{r}
# Get top authors by rating
# Filter by number of reviews
topAuth <- books_complete %>%
  filter(ratings_count > 500) %>%
  filter(!grepl(paste('/', collapse='|'), authors)) %>%
  filter(!grepl(paste('Anonymous', collapse='|'), authors))

# Extract only necessary columns
topAuth = topAuth[, c(2,3,4)]

# Group authors and calculate mean of their reviews
topAuth <- topAuth %>%
                group_by(authors) %>%
                dplyr::summarise(mean = mean(average_rating),
                      sd = sd(average_rating)) %>%
                mutate(cv = (sd/mean)*100)

# Limits decimal to 2 places
topAuth$mean <- format(round(topAuth$mean, 2), nsmall = 2)

# Removes unnecessary columns
topAuth <- topAuth[, -c(3,4)]

# Orders authors and pulls top 10 (code does not line "-" symbol to reverse order so tail is used instead of head)
topAuth <- topAuth %>% 
  arrange(mean) %>%
  tail(10)
```

```{r}
# Get books by top author
# Store author names in vector
topAuthNames <- c('Robert A. Caro', 'J.K. Rowling', 'Arthur Bennett', 'Michael  Wood', 'Don Rosa', 'Yoshitaka Amano', 'Fulton J. Sheen', 'Gary Russell', 'David Allen Sibley', 'Bill Watterson')

# Filter by number of reviews and books by top authors
topAuthBooks <- books_complete %>%
  filter(ratings_count > 500) %>%
  filter(!grepl(paste('/', collapse='|'), authors)) %>%
  filter(!grepl(paste(exclWords, collapse='|'), title)) %>%
  filter(grepl(paste(topAuthNames, collapse='|'), authors))

# Extract only necessary columns
topAuthBooks = topAuthBooks[, c(2,3,4)]
```

```{r}
# Bill Watterson book ratings vs average rating

# Get Bill Watterson books
billWBk <- topAuthBooks %>%
 filter(grepl(paste('Bill Watterson', collapse='|'), authors))

# Plot Bill Watterson books
billWPlot <-ggplot(data=billWBk, aes(x=average_rating, y=title)) +
  geom_bar(stat="identity", fill='steelblue4', width=0.5) +
  geom_text(aes(label=average_rating), hjust=1.3, color='white', size=3.5)+
  geom_vline(xintercept = 4.72, color="red") +
  ggtitle('Bill Watterson Book Ratings') +
  xlab('Average Rating') +
  ylab('Book Title')

billWPlot
```

```{r}
# J.K. Rowling book ratings vs average rating

# Get JK books
jkBk <- topAuthBooks %>%
 filter(grepl(paste('J.K. Rowling', collapse='|'), authors))

# Plot JK Rowling books
jkPlot <-ggplot(data=jkBk, aes(x=average_rating, y=title)) +
  geom_bar(stat="identity", fill='steelblue4', width=0.5) +
  geom_text(aes(label=average_rating), hjust=1.3, color='white', size=3.5)+
  geom_vline(xintercept = 4.53, color="red") +
  ggtitle('J.K. Rowling Book Ratings') +
  xlab('Average Rating') +
  ylab('Book Title')

jkPlot
```

```{r}
# Genre Pie Chart
# Rename certain genres to provide more accurate visualization
books_complete$genre[books_complete$genre == 'Fiction, general'] <- 'Fiction'
books_complete$genre[books_complete$genre == 'Fiction'] <- 'General Fiction'
books_complete$genre[books_complete$genre == 'Translations into English'] <- 'Foriegn Works'

# Counts frequency of genres, then filters based on genres that appear more than 5 times, then orders based on frequency
grGenres <- books_complete %>% 
  filter(!grepl(paste('n/a', collapse='|'), genre)) %>%
  count('genre') %>%
  subset(freq > 5) %>%
  arrange(-freq)

# Creates new df with top 10 genres
grGenresT10 <- grGenres[1:10,]
grGenresOther <- grGenres$freq[11:57] %>%
  sum()

# Adds row for "Other" category
grGenresT10[nrow(grGenresT10) + 1,] = c("Other",grGenresOther)

# Creates percentage column
grGenresT10$freq <- as.integer(grGenresT10$freq) 
grGenresT10 <- grGenresT10[order(grGenresT10$freq, decreasing=TRUE),]
grGenresSum <- sum(grGenresT10$freq)
grGenresT10$Percentage = mapply('/', grGenresT10$freq, grGenresSum)
  
# Creates foundation bar plot
genrePieBP <- ggplot(grGenresT10, aes(x="", y=freq, fill=genre))+
geom_bar(width = 1, stat = "identity", color = 'black')

# Creates pie chart
pie <- genrePieBP + coord_polar("y", start=0)
pie + scale_fill_brewer(palette="Set3") +
  coord_polar(theta = "y") +
  geom_text(aes(x=1.65, label = scales::percent(grGenresT10$Percentage, accuracy = .1)),
          position = position_stack(vjust = 0.5)) +
  coord_polar(theta = "y") +
  theme_void() +
  ggtitle('Genre Representation by Percentage')
```

```{r}
#Top 100 books with ratings greater than 4.5 stars
filter_books <- books_complete %>%
  filter(average_rating >=4.5)

# Bar plot of publishers with 3 or more books rated 4.5+
noPublishers <- filter_books %>% 
                  group_by(publisher) %>%
                  filter(n() > 3)

ggplot(noPublishers, aes(publisher)) +
    geom_bar(fill='steelblue4') + 
    labs(y = 'Number of Books 4.5+') +
    labs(x = 'Publishers') +
    ylim(0, 15) +
    theme(axis.text.x = element_text(angle = 45, size = 9,
        color = "black", face = "plain", vjust = 1, hjust = 1),
        plot.margin = margin(10, 10, 10, 100))
```

```{r}
# Filter out books with multiple authors (for clarity)
mostRated <- books_complete %>%
  filter(!grepl(paste('/', collapse='|'), authors)) %>%
  filter(!grepl(paste('Anonymous', collapse='|'), authors))

mostRated = mostRated[, c(3,9)]

mostRated <-  aggregate(ratings_count~.,mostRated,FUN=sum) %>%
  arrange(-ratings_count) %>%
  head(10)

mostRatedTopNames <- c('Dan Brown', 'Willliam Golding', 'Stephenie Meyer', 'Rick Riordan', 'Stephen King', 'John Steinbeck', 'J.R.R. Tolkien', 'J.D. Salinger', 'Jodi Picoult', 'Nicholas Sparks')

mostRatedBar <-ggplot(data=mostRated, aes(x=ratings_count, y=authors)) +
  geom_bar(stat="identity", fill='steelblue4') +
  scale_x_continuous(labels = scales::label_number_si()) +
  ggtitle('Most Rated Authors') +
  xlab('Number of Ratings') +
  ylab('Author')

mostRatedBar
```

```{r}
mostRatedAvg <- avgRatings %>%
 filter(grepl(paste(mostRatedTopNames, collapse='|'), authors))

mostRatedScatter <- merge(mostRated, mostRatedAvg, by='authors')

ggplot(mostRatedScatter, aes(x=mean, y=ratings_count)) + 
  geom_point(color='steelblue4') +
  geom_text(label=mostRatedScatter$authors, vjust=1.3) +
  scale_y_continuous(labels = scales::label_number_si()) +
  coord_cartesian(clip = "off") +
  ggtitle('Most Rated Authors - Rating Count vs. Average Rating') +
  xlab('Average Rating') +
  ylab('Number of Ratings')
```

```{r}

install.packages("neuralnet")
library(neuralnet)

library(caret)

set.seed(123)  # Set a seed for reproducibility
split <- createDataPartition(books_complete$average_rating, p = 0.7, list = FALSE)
train_data <- books_complete[split, ]
test_data <- books_complete[-split, ]

```

##

```{r}

```

```{r}
library(e1071)  # Load the e1071 package for SVM

svm_model <- svm(average_rating ~ num_pages + text_reviews_count, data = train_data, kernal = "radial")

```

```{r}


```
```{r}
predictions <- predict(svm_model, newdata = test_data)

# Calculate accuracy within a threshold
threshold <- 0.25
accuracy <- sum(abs(predictions - test_data$average_rating) <= threshold) / length(predictions)

# Print the modified accuracy
print(accuracy)

```

```{r}
predictions_binary <- ifelse(abs(predictions - test_data$average_rating) <= threshold, 1, 0)
true_values_binary <- ifelse(test_data$average_rating > threshold, 1, 0)

confusion_matrix <- table(predictions_binary, true_values_binary)
print(confusion_matrix)

```
```{r}
# Overall accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)

# Create a tool
as.percent <- function(x) {
  percent <- round(x * 100, 2)
  paste0(percent, "%")
}


# Print accuracy
cat("\n","Model is close (within a quarter star)", as.percent(accuracy),  "of the time")
